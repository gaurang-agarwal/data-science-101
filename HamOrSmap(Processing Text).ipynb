{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4c4163-8cf5-4603-8cec-803bdc71accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12362014-47b4-476d-b58f-f7964be39b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message  length  punct\n",
      "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
      "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
      "3   ham  U dun say so early hor... U c already then say...      49      6\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./resources/smsspamcollection.tsv', sep='\\t')\n",
    "print(df.head())\n",
    "X = df['message']\n",
    "y= df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40864a5-949e-4e85-b054-df137d90c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following is an example to use count vectorizer using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5875b6-73d0-4bd7-8fdb-1f9c964eaa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4814)\t1\n",
      "  (0, 3201)\t1\n",
      "  (0, 2948)\t1\n",
      "  (0, 6866)\t1\n",
      "  (0, 4628)\t1\n",
      "  (0, 3774)\t1\n",
      "  (0, 3786)\t1\n",
      "  (0, 4937)\t1\n",
      "  (0, 3620)\t1\n",
      "  (0, 4089)\t1\n",
      "  (0, 3666)\t1\n",
      "  (0, 961)\t1\n",
      "  (0, 3534)\t1\n",
      "  (1, 3620)\t1\n",
      "  (1, 7756)\t1\n",
      "  (1, 7507)\t1\n",
      "  (1, 1052)\t1\n",
      "  (1, 2995)\t1\n",
      "  (1, 1630)\t1\n",
      "  (1, 3163)\t1\n",
      "  (1, 5026)\t1\n",
      "  (1, 4701)\t1\n",
      "  (1, 820)\t1\n",
      "  (1, 2608)\t1\n",
      "  (1, 4721)\t1\n",
      "  :\t:\n",
      "  (4454, 376)\t1\n",
      "  (4454, 655)\t1\n",
      "  (4454, 4630)\t1\n",
      "  (4454, 2125)\t1\n",
      "  (4454, 110)\t1\n",
      "  (4454, 351)\t1\n",
      "  (4455, 3620)\t1\n",
      "  (4455, 3666)\t1\n",
      "  (4455, 1630)\t1\n",
      "  (4455, 7460)\t2\n",
      "  (4455, 4684)\t1\n",
      "  (4455, 3536)\t1\n",
      "  (4455, 3181)\t1\n",
      "  (4455, 4447)\t1\n",
      "  (4455, 5932)\t1\n",
      "  (4455, 2500)\t1\n",
      "  (4456, 3137)\t1\n",
      "  (4456, 2194)\t1\n",
      "  (4456, 6862)\t1\n",
      "  (4456, 6993)\t1\n",
      "  (4456, 6099)\t1\n",
      "  (4456, 2806)\t1\n",
      "  (4456, 3794)\t1\n",
      "  (4456, 4554)\t1\n",
      "  (4456, 6272)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train_counts = count_vect.fit_transform(X_train);\n",
    "print(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "394a8a40-6861-4d15-b0c8-4fcbe4ab8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer #Combination of TfidfTransofrmer and CountVectorizer\n",
    "tf_vec = TfidfVectorizer()\n",
    "X_train_idf = tf_vec.fit_transform(X_train)\n",
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC()\n",
    "model.fit(X_train_idf,y_train);\n",
    "X_test_idf = tf_vec.transform(X_test)\n",
    "y_predict = model.predict(X_test_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d286399-eada-485d-9872-d9a79e89e08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[954   1]\n",
      " [  9 151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       955\n",
      "        spam       0.99      0.94      0.97       160\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.99      0.97      0.98      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n",
      "0.9910313901345291\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,y_predict))\n",
    "print(metrics.classification_report(y_test,y_predict))\n",
    "print(metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b9f73-ff0d-4fa8-944b-b8a1638ad7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cae75b5-f5ca-439b-889b-348820fbbd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[954   1]\n",
      " [  9 151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       955\n",
      "        spam       0.99      0.94      0.97       160\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.99      0.97      0.98      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n",
      "0.9910313901345291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a custom transformer to extract other features (if any)\n",
    "class ItemSelector(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"This class allows you to select a subset of a dataframe based on given column name(s).\"\"\"\n",
    "    def __init__(self, keys):\n",
    "        self.keys = keys\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, dataframe):\n",
    "        return dataframe[self.keys]\n",
    "        \n",
    "# Define a custom transformer to extract other features (if any)\n",
    "class OtherFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Transform other features\n",
    "        return X[['length', 'punct']].values  # Assuming these are the other features\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "    ('features', \n",
    "     FeatureUnion\n",
    "     (\n",
    "        transformer_list=\n",
    "         [\n",
    "            ('bag-of-words', Pipeline([\n",
    "                ('selector', ItemSelector(keys='message')),\n",
    "                ('vectorizer', TfidfVectorizer()),\n",
    "            ]))\n",
    "            #  ,\n",
    "            # ('votes', Pipeline([\n",
    "            #     ('selector', ItemSelector(keys=['length', 'punct'])),\n",
    "            #     ('other_features', OtherFeatureExtractor())\n",
    "            # ]))\n",
    "         ],\n",
    "         transformer_weights={\n",
    "            'bag-of-words': 1.0,\n",
    "            # 'votes': 0.1\n",
    "        },\n",
    "     )\n",
    "    ),\n",
    "    ('classifier', LinearSVC())  # Classifier\n",
    "])\n",
    "df = pd.read_csv('./resources/smsspamcollection.tsv', sep='\\t')\n",
    "X = df[['message', 'length', 'punct']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Fit the pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained pipeline\n",
    "y_predict = pipeline.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,y_predict))\n",
    "print(metrics.classification_report(y_test,y_predict))\n",
    "print(metrics.accuracy_score(y_test,y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60381ab9-230e-4823-92da-7b485d91eea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_spacy",
   "language": "python",
   "name": "nlp_spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
